{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-15T12:25:25.770013Z",
     "start_time": "2018-03-15T12:25:17.228835Z"
    }
   },
   "outputs": [],
   "source": [
    "# 将所有特征串联起来，构成RS_Train.csv\n",
    "#RS_Test.csv\n",
    "#为最后推荐系统做准备\n",
    "#from __future__ import division\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import scipy.sparse as ss\n",
    "from numpy.random import random  \n",
    "from collections import defaultdict\n",
    "import scipy.spatial.distance as ssd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 清理内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-15T13:46:09.861055Z",
     "start_time": "2018-03-15T13:46:09.813521Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "###好多代码###\n",
    "###好多代码###\n",
    "#del aaa\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-15T12:25:49.461783Z",
     "start_time": "2018-03-15T12:25:49.455779Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-15T13:53:16.321501Z",
     "start_time": "2018-03-15T13:53:12.243596Z"
    }
   },
   "outputs": [],
   "source": [
    "class RecommonderSystem(object):\n",
    "    def __init__(self):\n",
    "        # 读入数据做初始化\n",
    "        # 数据地址\n",
    "        self.dpath = './data/'\n",
    "        #用户和活动新的索引\n",
    "        self.userIndex  = pickle.load(open(self.dpath+\"PE_userIndex.pkl\", 'rb'))\n",
    "        self.eventIndex = pickle.load(open(self.dpath+\"PE_eventIndex.pkl\", 'rb'))\n",
    "        self.n_users = len(self.userIndex)\n",
    "        self.n_items = len(self.eventIndex)\n",
    "\n",
    "        #用户-活动关系矩阵R\n",
    "        #在train_SVD会重新从文件中读取,二者要求的格式不同，来不及统一了:(\n",
    "        '''getrow(userIndex[]).getcol(eventIndex[])==1,感兴趣'''\n",
    "        self.userEventScores = sio.mmread(self.dpath+\"PE_userEventScores\").todense()\n",
    "\n",
    "        #倒排表(defaultdict)\n",
    "        ''' {userIndex: eventIndex***}  {eventIndex: userIndex***}  '''\n",
    "        ##每个用户参加的事件\n",
    "        self.itemsForUser = pickle.load(open(self.dpath+\"PE_eventsForUser.pkl\", 'rb'))\n",
    "        ##事件参加的用户\n",
    "        self.usersForItem = pickle.load(open(self.dpath+\"PE_usersForEvent.pkl\", 'rb'))\n",
    "\n",
    "        #根据活动属性计算出的活动之间的相似度\n",
    "        '''#getrow(eventIndex[])代表该event与哪些event相似,相似度是多少'''\n",
    "        self.eventPropSim = sio.mmread(self.dpath+\"EV_eventPropSim\").todense()\n",
    "        self.eventContSim = sio.mmread(self.dpath+\"EV_eventContSim\").todense()\n",
    "\n",
    "        #根据用户属性计算出的用户之间的相似度\n",
    "        '''getrow(userIndex[])代表该user与哪些user相似,相似度是多少'''\n",
    "        self.userSimMatrix = sio.mmread(self.dpath+\"US_userSimMatrix\").todense()\n",
    "\n",
    "        #每个用户的朋友的数目\n",
    "        '''#numFriends[:,userIndex[]]该user拥有的朋友的数量'''\n",
    "        self.numFriends = sio.mmread(self.dpath+\"UF_numFriends\")\n",
    "        #用户的每个朋友参加活动的分数对该用户的影响\n",
    "        '''#getrow(userIndex[])代表该user有哪些朋友,值代表朋友参加活动的数量'''\n",
    "        self.userFriends = sio.mmread(self.dpath+\"UF_userFriends\").todense()\n",
    "\n",
    "        #活动本身的热度\n",
    "        '''#getrow(eventIndex[])代表该event有哪些user参加, 值代表参加event的user的数量'''\n",
    "        self.eventPopularity = sio.mmread(self.dpath+\"EA_eventPopularity\").todense()\n",
    "        \n",
    "        #提前训练模型\n",
    "        self.init_SVD()\n",
    "        self.train_SVD(trainfile=self.dpath+'train.csv')\n",
    "\n",
    "    def init_SVD(self, K=25):\n",
    "        #初始化模型参数（for 基于模型的协同过滤SVD_CF）\n",
    "        self.K = K  \n",
    "\n",
    "        #init parameters\n",
    "        #bias\n",
    "        self.bi = np.zeros(self.n_items)  \n",
    "        self.bu = np.zeros(self.n_users)  \n",
    "\n",
    "        #the small matrix\n",
    "        self.P = random((self.n_users,self.K))/10*(np.sqrt(self.K))\n",
    "        self.Q = random((self.K, self.n_items))/10*(np.sqrt(self.K))  \n",
    "\n",
    "\n",
    "    def train_SVD(self,trainfile = 'train.csv', steps=100 ,gamma=0.04,Lambda=0.15):\n",
    "        #训练SVD模型（for 基于模型的协同过滤SVD_CF）\n",
    "        #gamma：为学习率\n",
    "        #Lambda：正则参数\n",
    "        #偷懒了，为了和原来的代码的输入接口一样，直接从训练文件中去读取数据\n",
    "        print(\"SVD Train...\")\n",
    "        ftrain = open(trainfile, 'r')\n",
    "        ftrain.readline()\n",
    "        self.mu = 0.0\n",
    "        n_records = 0\n",
    "        u_ids = []  #每条记录的用户索引\n",
    "        i_ids = [] #每条记录的item索引\n",
    "        #用户-Item关系矩阵R（内容同userEventScores相同），临时变量，训练完了R不再需要\n",
    "        R = np.zeros((self.n_users, self.n_items))\n",
    "\n",
    "        for line in ftrain:\n",
    "            cols = line.strip().split(\",\")\n",
    "            u = self.userIndex[cols[0]]  #用户\n",
    "            i = self.eventIndex[cols[1]] #活动\n",
    "\n",
    "            u_ids.append(u)\n",
    "            i_ids.append(i)\n",
    "\n",
    "            R[u,i] = int(cols[4])  #interested\n",
    "            self.mu += R[u,i] #感兴趣的次数\n",
    "            n_records += 1    #共有多少条记录\n",
    "\n",
    "        ftrain.close()\n",
    "        self.mu /= n_records\n",
    "\n",
    "        # 请补充完整SVD模型训练过程\n",
    "        '''*************************************************************************************'''\n",
    "        #self.P 和self.Q 均已初始化为随机数\n",
    "        #self.bi和self.bu均已初始化为0\n",
    "        \n",
    "        for step in range(steps):\n",
    "            rmse_sum=0.0  \n",
    "            #产生随机数\n",
    "            kku=np.random.permutation(len(u_ids))\n",
    "            kki=np.random.permutation(len(i_ids))\n",
    "            for j in range(len(u_ids)):\n",
    "                #获得随机的u和i\n",
    "                u = u_ids[kku[j]]\n",
    "                i = i_ids[kki[j]]\n",
    "                #损失函数\n",
    "                e_ui = R[u,i] - self.pred_SVD(u,i)\n",
    "                rmse_sum += e_ui**2\n",
    "                #更新公式\n",
    "                self.bu[u] += gamma*(e_ui-Lambda*self.bu[u])\n",
    "                self.bi[i] += gamma*(e_ui-Lambda*self.bi[i])\n",
    "                temp=self.Q[:,i]\n",
    "                self.Q[:,i] += gamma*(e_ui*self.P[u,:] - Lambda*self.Q[:,i])\n",
    "                self.P[u,:] += gamma*(e_ui*temp - Lambda*self.P[u,:])\n",
    "            #学习率递减\n",
    "            gamma=gamma*0.95\n",
    "            if step%10==0:\n",
    "                print(\"rmse in step(%d) is :%f \"%(step,np.sqrt(rmse_sum/len(u_ids))))\n",
    "\n",
    "        print(\"the final rmse is: \",np.sqrt(rmse_sum/len(u_ids)))\n",
    "        print(\"SVD trained ^*^\")\n",
    "            \n",
    "    def pred_SVD(self, u_id, i_id):\n",
    "        #根据当前参数，预测用户uid对Item（i_id）的打分        \n",
    "        ans=self.mu + self.bi[i_id] + self.bu[u_id] + np.dot(self.P[u_id,:],self.Q[:,i_id])  \n",
    "\n",
    "        #将打分范围控制在0-1之间\n",
    "        if ans>1:  \n",
    "            return 1  \n",
    "        elif ans<0:  \n",
    "            return 0\n",
    "        return ans  \n",
    "\n",
    "    def svdCFReco(self, userId, eventId):\n",
    "        #基于模型的协同过滤, SVD++/LFM\n",
    "        u = self.userIndex[userId]\n",
    "        i = self.eventIndex[eventId]\n",
    "\n",
    "        return self.pred_SVD(u,i)\n",
    "\n",
    "    def sim_cal_UserCF(self, uid1, uid2 ):\n",
    "        #请补充基于用户的协同过滤中的两个用户uid1和uid2之间的相似度\n",
    "        #（根据两个用户对item打分的相似度）\n",
    "        '''****************************************************************************************'''\n",
    "        similarity=0.0\n",
    "        #有效的event(uid1和uid2均有打分的event)\n",
    "        P=self.itemsForUser[uid1]&self.itemsForUser[uid2]\n",
    "        if len(P)<1: #如果两user无共同event, 返回simlarity=0.0\n",
    "            return similarity\n",
    "\n",
    "        r1=self.userEventScores[uid1,:].sum()/len(self.itemsForUser[uid1])\n",
    "        r2=self.userEventScores[uid2,:].sum()/len(self.itemsForUser[uid2])\n",
    "        rpa=0\n",
    "        rpb=0\n",
    "        rpab=0\n",
    "        for p in P:\n",
    "            ra=self.userEventScores[uid1,p]-r1\n",
    "            rb=self.userEventScores[uid2,p]-r2\n",
    "            rpa +=ra**2\n",
    "            rpb +=rb**2\n",
    "            rpab+=rpa*rpb\n",
    "        \n",
    "        if rpa*rpb ==0:#\n",
    "            return similarity\n",
    "        else:\n",
    "            similarity = rpab/(np.sqrt(rpa)*np.sqrt(rpb))\n",
    "        return similarity  \n",
    "\n",
    "    def userCFReco(self, userId, eventId):\n",
    "        \"\"\"\n",
    "        根据User-based协同过滤，得到event的推荐度\n",
    "        基本的伪代码思路如下：\n",
    "        for item i\n",
    "          for every other user v that has a preference for i\n",
    "            compute similarity s between u and v\n",
    "            incorporate v's preference for i weighted by s into running average\n",
    "        return top items ranked by weighted average\n",
    "        \"\"\"\n",
    "        #请补充完整代码\n",
    "        '''******************************************************************************************'''\n",
    "        ans = 0.0\n",
    "        u=self.userIndex[userId]\n",
    "        i=self.eventIndex[eventId]\n",
    "        \n",
    "        if len(self.itemsForUser[u])>0:\n",
    "            ave_u=self.userEventScores[u,:].sum()/len(self.itemsForUser[u])\n",
    "        else:\n",
    "            ave_u=0\n",
    "        vs=self.usersForItem[i]#出席该活动的用户有哪些\n",
    "        sims=0\n",
    "        \n",
    "        for v in vs:\n",
    "            sim=self.sim_cal_UserCF(u,v)\n",
    "            if len(self.itemsForUser[v])>0:\n",
    "                ave=self.userEventScores[v,:].sum()/len(self.itemsForUser[v])\n",
    "            else:\n",
    "                ave=0\n",
    "            ans+=sim*(self.userEventScores[v,i]-ave)\n",
    "            sims+=sim\n",
    "        \n",
    "        if sims>0:\n",
    "            ans=ans/sims\n",
    "        else:\n",
    "            ans=0.0\n",
    "#        print(sims)  \n",
    "        return ans+ave_u\n",
    "\n",
    "\n",
    "\n",
    "    def sim_cal_ItemCF(self, iid1, iid2):\n",
    "        #计算Item i_id1和i_id2之间的相似性\n",
    "        #请补充完整代码\n",
    "        '''******************************************************************************************'''\n",
    "        similarity=0.0\n",
    "        U=self.usersForItem[iid1]&self.usersForItem[iid2]\n",
    "        if len(U)<1: #如果两event无共同user, 返回simlarity=0.0\n",
    "            return similarity\n",
    "\n",
    "        rua=0\n",
    "        rub=0\n",
    "        ruab=0\n",
    "        for u in U:\n",
    "            ru=self.userEventScores[u,:].sum()/len(self.itemsForUser[u])\n",
    "            ra=self.userEventScores[u,iid1]\n",
    "            rb=self.userEventScores[u,iid2]\n",
    "            rua +=(ra-ru)**2\n",
    "            rub +=(rb-ru)**2\n",
    "            ruab+=(ra-ru)*(rb-ru)\n",
    "        if rua*rub ==0:\n",
    "            return similarity\n",
    "        else:\n",
    "            similarity = ruab/(np.sqrt(rua)*np.sqrt(rub))\n",
    "        return similarity  \n",
    "    \n",
    "    def eventCFReco(self, userId, eventId):    \n",
    "        \"\"\"\n",
    "        根据基于物品的协同过滤，得到Event的推荐度\n",
    "        基本的伪代码思路如下：\n",
    "        for item i \n",
    "            for every item j that u has a preference for\n",
    "                compute similarity s between i and j\n",
    "                add u's preference for j weighted by s to a running average\n",
    "        return top items, ranked by weighted average\n",
    "        \"\"\"\n",
    "        #请补充完整代码\n",
    "        '''*****************************************************************************************'''\n",
    "        ans = 0.0\n",
    "        sims=0\n",
    "        u=self.userIndex[userId]\n",
    "        i=self.eventIndex[eventId]\n",
    "        js=self.itemsForUser[u]#该用户出席的活动有哪些\n",
    "        for j in js:\n",
    "            sim=self.sim_cal_ItemCF(i,j)\n",
    "            ans+=sim*self.userEventScores[u,j]\n",
    "            sims+=sim\n",
    "\n",
    "        if sims>0:\n",
    "            ans=ans/sims\n",
    "        else:\n",
    "            ans=0.0\n",
    "#        print(sims)\n",
    "        return ans\n",
    "    \n",
    "\n",
    "    def userReco(self, userId, eventId):\n",
    "        \"\"\"\n",
    "        类似基于User-based协同过滤，只是用户之间的相似度由用户本身的属性得到，\n",
    "        计算event的推荐度, 基本的伪代码思路如下：\n",
    "        for item i\n",
    "          for every other user v that has a preference for i\n",
    "            compute similarity s between u and v\n",
    "            incorporate v's preference for i weighted by s into running average\n",
    "        return top items ranked by weighted average\n",
    "        \"\"\"\n",
    "        i = self.userIndex[userId]\n",
    "        j = self.eventIndex[eventId]\n",
    "\n",
    "        vs = self.userEventScores[:, j]\n",
    "        #[user,event]==1 有兴趣\n",
    "        sims = self.userSimMatrix[i, :]\n",
    "        #[user,user]=sim\n",
    "        prod = sims * vs\n",
    "        #标量, 内积\n",
    "\n",
    "        try:\n",
    "            return prod[0, 0] - self.userEventScores[i, j]\n",
    "        except IndexError:\n",
    "            return 0 #该user对该event不感兴趣\n",
    "\n",
    "    def eventReco(self, userId, eventId):\n",
    "        \"\"\"\n",
    "        类似基于Item-based协同过滤，只是item之间的相似度由item本身的属性得到，\n",
    "        计算Event的推荐度, 基本的伪代码思路如下：\n",
    "        for item i \n",
    "          for every item j that u has a preference for\n",
    "            compute similarity s between i and j\n",
    "            add u's preference for j weighted by s to a running average\n",
    "        return top items, ranked by weighted average\n",
    "        \"\"\"\n",
    "        i = self.userIndex[userId]\n",
    "        j = self.eventIndex[eventId]\n",
    "        js = self.userEventScores[i, :]\n",
    "        psim = self.eventPropSim[:, j]\n",
    "        csim = self.eventContSim[:, j]\n",
    "        pprod = js * psim\n",
    "        cprod = js * csim\n",
    "\n",
    "        pscore = 0\n",
    "        cscore = 0\n",
    "        try:\n",
    "            pscore = pprod[0, 0] - self.userEventScores[i, j]\n",
    "        except IndexError:\n",
    "            pass\n",
    "        try:\n",
    "            cscore = cprod[0, 0] - self.userEventScores[i, j]\n",
    "        except IndexError:\n",
    "            pass\n",
    "        return pscore, cscore\n",
    "\n",
    "    def userPop(self, userId):\n",
    "        \"\"\"\n",
    "        基于用户的朋友个数来推断用户的社交程度\n",
    "        主要的考量是如果用户的朋友非常多，可能会更倾向于参加各种社交活动\n",
    "        \"\"\"\n",
    "        if userId in self.userIndex.keys():\n",
    "            i = self.userIndex[userId]\n",
    "            try:\n",
    "                return self.numFriends[0, i]\n",
    "            except IndexError:\n",
    "                return 0\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def friendInfluence(self, userId):\n",
    "        \"\"\"\n",
    "        朋友对用户的影响\n",
    "        主要考虑用户所有的朋友中，有多少是非常喜欢参加各种社交活动/event的\n",
    "        用户的朋友圈如果都积极参与各种event，可能会对当前用户有一定的影响\n",
    "        \"\"\"\n",
    "        nusers = np.shape(self.userFriends)[1]\n",
    "        i = self.userIndex[userId]\n",
    "        return (self.userFriends[i, :].sum(axis=0) / nusers)[0,0]\n",
    "\n",
    "    def eventPop(self, eventId):\n",
    "        \"\"\"\n",
    "        本活动本身的热度\n",
    "        主要是通过参与的人数来界定的\n",
    "        \"\"\"\n",
    "        i = self.eventIndex[eventId]\n",
    "        return self.eventPopularity[i, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-15T13:53:56.371243Z",
     "start_time": "2018-03-15T13:53:16.585678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Train...\n",
      "rmse in step(0) is :0.878583 \n",
      "rmse in step(10) is :0.087902 \n",
      "rmse in step(20) is :0.072326 \n",
      "rmse in step(30) is :0.063370 \n",
      "rmse in step(40) is :0.065977 \n",
      "rmse in step(50) is :0.066528 \n",
      "rmse in step(60) is :0.061517 \n",
      "rmse in step(70) is :0.063990 \n",
      "rmse in step(80) is :0.059413 \n",
      "rmse in step(90) is :0.062049 \n",
      "the final rmse is:  0.05995514121017157\n",
      "SVD trained ^*^\n"
     ]
    }
   ],
   "source": [
    "RS = RecommonderSystem()\n",
    "dpath = './data/'\n",
    "#用户和活动新的索引\n",
    "userIndex  = pickle.load(open(dpath+\"PE_userIndex.pkl\", 'rb'))\n",
    "eventIndex = pickle.load(open(dpath+\"PE_eventIndex.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-15T13:57:19.350805Z",
     "start_time": "2018-03-15T13:57:19.345299Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nan==np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-15T13:55:47.648486Z",
     "start_time": "2018-03-15T13:55:06.993963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.00029254022428082394 -0.25\n",
      "0.3714285714285714 1.0\n",
      "0.39999999999999997 1.0\n",
      "0.3454545454545454 1.0\n",
      "0.3 1.0\n",
      "0.33333333333333337 1.0\n",
      "0.29761904761904767 1.0\n",
      "0.0892857142857143 0.5\n",
      "0.0892857142857143 1.0\n",
      "0.3492063492063492 1.0\n",
      "0.15476190476190477 1.0\n",
      "0.07142857142857142 0.5\n",
      "0.47619047619047616 0.5\n",
      "0.4502164502164502 1.0\n",
      "0.19047619047619047 1.0\n",
      "0.12698412698412698 1.0\n",
      "0.27976190476190477 0.5\n",
      "0.23809523809523808 0.5\n",
      "0.19047619047619047 1.0\n",
      "0.07142857142857142 1.0\n",
      "0.40476190476190477 0.5\n",
      "0.3492063492063492 1.0\n",
      "0.07142857142857142 1.0\n",
      "0.07142857142857142 1.0\n",
      "0.07142857142857142 1.0\n",
      "0.07142857142857142 1.0\n",
      "0.07142857142857142 1.0\n",
      "0.07142857142857142 1.0\n",
      "0.07142857142857142 1.0\n",
      "0.5047619047619047 1.0\n",
      "0.40476190476190477 1.0\n",
      "0.07142857142857142 1.0\n",
      "0.23809523809523808 0.5\n",
      "0.19047619047619047 1.0\n",
      "0.10476190476190478 1.0\n",
      "0.4502164502164502 0.3333333333333333\n",
      "0.07142857142857142 1.0\n",
      "0.257703081232493 1.0\n",
      "0.3492063492063492 0.5\n",
      "0.5201465201465202 1.0\n",
      "0.47619047619047616 1.0\n",
      "0.36630036630036633 1.0\n",
      "0.07142857142857142 1.0\n",
      "0.07142857142857142 1.0\n",
      "0.3492063492063492 0.5\n",
      "0.07142857142857142 1.0\n",
      "0.15476190476190477 1.0\n",
      "0.3666666666666666 1.0\n",
      "1.0128135696528666 1.3969947556801345\n",
      "0.9523809523809522 1.0\n",
      "0.2777777777777778 1.0\n",
      "0.20833333333333334 0.5\n",
      "0.43333333333333335 1.0\n",
      "0.4487179487179488 1.0\n",
      "0.40476190476190477 1.0\n",
      "0.11904761904761904 1.0\n",
      "-0.03382976091058121 -0.6666666666666666\n",
      "0.33868311800369305 0.5\n",
      "-0.34543926920641177 -30.760151470981224\n",
      "-0.19914804632836014 -0.46633999724420694\n",
      "-0.1656869212879179 -1.0220735205967986\n",
      "0.047619047619047616 1.0\n",
      "-0.22735607872538588 -30.760151470981224\n",
      "-0.34543926920641177 -30.760151470981224\n",
      "-0.08165672565889537 -0.5605096120569012\n",
      "-0.34543926920641177 -30.760151470981224\n",
      "-0.12673046059089715 -1.5475592250620471\n",
      "0.09653291941155795 1.0\n",
      "-0.11776616375786608 -2.624289343912555\n",
      "0.15544466285159886 1.8876744386079107\n",
      "-0.20207159835137284 -2.424325439363635\n",
      "-0.34543926920641177 -30.760151470981224\n",
      "0.2142857142857143 1.0\n",
      "-0.10838916686366118 -2.624289343912555\n",
      "-0.22735607872538588 -30.760151470981224\n",
      "-0.3691488242686925 -30.760151470981224\n",
      "0.2857142857142857 1.0\n",
      "-0.3239446527566434 -0.7121627196818178\n",
      "-0.22953043988008023 -0.09820447718949496\n",
      "0.31478930373709335 1.0\n",
      "0.10614830402694264 1.0\n",
      "-0.07213242765978889 -30.760151470981224\n",
      "0.2142857142857143 1.0\n",
      "-0.34543926920641177 -30.760151470981224\n",
      "0.08188441794999168 1.0\n",
      "-0.38694554680505444 -30.760151470981224\n",
      "0.41666666666666674 1.0\n",
      "0.1111111111111111 0.5\n",
      "0.16666666666666669 1.0\n",
      "0.25000000000000006 1.0\n",
      "0.13333333333333336 1.0\n",
      "0.19607843137254904 1.0\n",
      "0.1111111111111111 1.0\n",
      "0.041666666666666685 1.0\n",
      "0.16666666666666669 1.0\n",
      "0.16666666666666669 1.0\n",
      "0.25000000000000006 1.0\n",
      "0.1111111111111111 0.5\n",
      "0.041666666666666685 1.0\n",
      "0.041666666666666685 0.5\n",
      "0.16666666666666669 1.0\n",
      "0.1111111111111111 1.0\n",
      "0.28205128205128216 0.5\n",
      "0.4166666666666667 1.0\n",
      "0.1111111111111111 1.0\n",
      "0.06203007518796988 0.25\n",
      "0.3217703349282296 1.0\n",
      "-2.7755575615628914e-17 -0.40476190476190477\n",
      "-0.06832099377050116 -2.2114453909408303\n",
      "-0.07589464569260937 -0.711052725381524\n",
      "-0.10665867261259912 -2.6588364808536804\n",
      "0.24159210647803792 0.21464586793498303\n",
      "-0.06832099377050116 -2.2114453909408303\n",
      "0.3540206009916604 3.6588364808536804\n",
      "0.31084781404866707 1.0\n",
      "0.05555555555555558 1.0\n",
      "-0.09378823642571096 -0.5707082641300341\n",
      "-0.0922011079472011 -2.2114453909408303\n",
      "-0.058607213081325854 -0.4056968871614771\n",
      "0.08062429962154993 1.0\n",
      "0.04385964912280707 1.0\n",
      "0.4748550688523192 1.0\n",
      "0.25814536340852134 1.0\n",
      "-0.07950721972769886 -2.2114453909408303\n",
      "-0.11457212723670632 -0.5469569948052703\n",
      "1.0 1.6153846153846154\n",
      "0.6666666666666666 1.0\n",
      "0.7 1.0\n",
      "0.9 1.0\n",
      "0.7857142857142857 1.0\n",
      "0.6666666666666666 1.0\n",
      "0.6666666666666666 1.0\n",
      "0.05555555555555558 1.0\n",
      "-0.08333333333333334 -1.0\n",
      "0.17045454545454536 1.0\n",
      "-0.0005994505037049125 -1.5\n",
      "0.15873015873015872 1.0\n",
      "0.3142857142857143 1.0\n",
      "0.2142857142857143 1.0\n",
      "0.3296703296703298 1.0\n",
      "0.2857142857142857 1.0\n",
      "0.43333333333333335 1.0\n",
      "0.20833333333333334 1.0\n",
      "0.11904761904761904 1.0\n",
      "0.11904761904761904 1.0\n",
      "0.43333333333333335 1.0\n",
      "0.15873015873015872 1.0\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "\n",
    "for eventId in eventIndex.keys():\n",
    "    for userId in userIndex.keys():\n",
    "        itemCF_reco = RS.eventCFReco(userId, eventId)\n",
    "        userCF_reco = RS.userCFReco(userId, eventId)\n",
    "        i+=1\n",
    "        if i>300000:\n",
    "            break\n",
    "        if (itemCF_reco*userCF_reco>0):#&(itemCF_reco<0.99):\n",
    "            print(userCF_reco,itemCF_reco)#,svdCF_reco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-15T13:31:05.194903Z",
     "start_time": "2018-03-15T13:31:05.115846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.375, 0.0, 0.18165556307742856], [0.0, 0.0, 0.0], [0.001229036894422622, 0.0, -2.990671405730587e-05]]\n"
     ]
    }
   ],
   "source": [
    "userId = '3724535659'\n",
    "eventId= '2338670339'\n",
    "\n",
    "userCF_reco = RS.userCFReco(userId, eventId)\n",
    "itemCF_reco = RS.eventCFReco(userId, eventId)\n",
    "svdCF_reco = RS.svdCFReco(userId, eventId)\n",
    "        \n",
    "user_reco = RS.userReco(userId, eventId)\n",
    "evt_p_reco, evt_c_reco = RS.eventReco(userId, eventId)\n",
    "user_pop = RS.userPop(userId)\n",
    "     \n",
    "frnd_infl = RS.friendInfluence(userId)\n",
    "evt_pop = RS.eventPop(eventId)\n",
    "ocols = [[userCF_reco, itemCF_reco, svdCF_reco],\n",
    "         [user_reco, evt_p_reco, evt_c_reco],\n",
    "         [user_pop, frnd_infl, evt_pop]]\n",
    "print(ocols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-15T02:38:17.617851Z",
     "start_time": "2018-03-15T02:38:17.604834Z"
    }
   },
   "source": [
    "#del rs\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-15T13:31:15.797110Z",
     "start_time": "2018-03-15T13:31:15.647498Z"
    }
   },
   "outputs": [],
   "source": [
    "def generateRSData(RS, train=True, header=True):\n",
    "    \"\"\"\n",
    "    把前面user-based协同过滤 和 item-based协同过滤，以及各种热度和影响度作为特征组合在一起\n",
    "    生成新的训练数据，用于分类器分类使用\n",
    "    \"\"\"\n",
    "    dpath = './data/'\n",
    "    fn = \"train.csv\" if train else \"test.csv\"\n",
    "    fin = open(dpath+fn, 'r')\n",
    "    fout = open(dpath+\"RS_\" + fn, 'w')\n",
    "    \n",
    "    #忽略第一行（列名字）\n",
    "    fin.readline().strip().split(\",\")\n",
    "    \n",
    "    # write output header\n",
    "    if header:\n",
    "        ocolnames = [\"invited\", \"userCF_reco\", \"evtCF_reco\"\n",
    "                     , \"svdCF_reco\",\"user_reco\", \"evt_p_reco\", \"evt_c_reco\"\n",
    "                     , \"user_pop\", \"frnd_infl\", \"evt_pop\"]\n",
    "        if train:\n",
    "            ocolnames.append(\"interested\")\n",
    "            ocolnames.append(\"not_interested\")\n",
    "        fout.write(\",\".join(ocolnames) + \"\\n\")\n",
    "    \n",
    "    ln = 0\n",
    "    for line in fin:\n",
    "        ln += 1\n",
    "        if ln%500 == 0:\n",
    "            print(\"%s:%d (userId, eventId)=(%s, %s)\" % (fn, ln, userId, eventId))\n",
    "            #break;\n",
    "      \n",
    "        cols = line.strip().split(\",\")\n",
    "        userId = cols[0]\n",
    "        eventId = cols[1]\n",
    "        invited = cols[2]\n",
    "      \n",
    "        userCF_reco = RS.userCFReco(userId, eventId)\n",
    "        itemCF_reco = RS.eventCFReco(userId, eventId)\n",
    "        svdCF_reco = RS.svdCFReco(userId, eventId)\n",
    "        \n",
    "        user_reco = RS.userReco(userId, eventId)\n",
    "        evt_p_reco, evt_c_reco = RS.eventReco(userId, eventId)\n",
    "        user_pop = RS.userPop(userId)\n",
    "     \n",
    "        frnd_infl = RS.friendInfluence(userId)\n",
    "        evt_pop = RS.eventPop(eventId)\n",
    "        ocols = [invited, userCF_reco, itemCF_reco, svdCF_reco\n",
    "                 , user_reco, evt_p_reco,evt_c_reco\n",
    "                 , user_pop, frnd_infl, evt_pop]\n",
    "      \n",
    "        if train:\n",
    "            ocols.append(cols[4]) # interested\n",
    "            ocols.append(cols[5]) # not_interested\n",
    "        fout.write(\",\".join(map(lambda x: str(x), ocols)) + \"\\n\")\n",
    "    \n",
    "    fin.close()\n",
    "    fout.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-15T13:40:37.989221Z",
     "start_time": "2018-03-15T13:37:22.451565Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Train...\n",
      "rmse in step(0) is :0.879424 \n",
      "rmse in step(10) is :0.087057 \n",
      "rmse in step(20) is :0.073921 \n",
      "rmse in step(30) is :0.063484 \n",
      "rmse in step(40) is :0.054978 \n",
      "rmse in step(50) is :0.065881 \n",
      "rmse in step(60) is :0.058096 \n",
      "rmse in step(70) is :0.058405 \n",
      "rmse in step(80) is :0.065264 \n",
      "rmse in step(90) is :0.060327 \n",
      "the final rmse is:  0.05968812870406094\n",
      "SVD trained ^*^\n",
      "生成训练数据...\n",
      "\n",
      "train.csv:500 (userId, eventId)=(123290209, 1887085024)\n",
      "train.csv:1000 (userId, eventId)=(272886293, 199858305)\n",
      "train.csv:1500 (userId, eventId)=(395305791, 1582270949)\n",
      "train.csv:2000 (userId, eventId)=(527523423, 3272728211)\n",
      "train.csv:2500 (userId, eventId)=(651258472, 792632006)\n",
      "train.csv:3000 (userId, eventId)=(811791433, 524756826)\n",
      "train.csv:3500 (userId, eventId)=(985547042, 1269035551)\n",
      "train.csv:4000 (userId, eventId)=(1107615001, 173949238)\n",
      "train.csv:4500 (userId, eventId)=(1236336671, 3849306291)\n",
      "train.csv:5000 (userId, eventId)=(1414301782, 2652356640)\n",
      "train.csv:5500 (userId, eventId)=(1595465532, 955398943)\n",
      "train.csv:6000 (userId, eventId)=(1747091728, 2131379889)\n",
      "train.csv:6500 (userId, eventId)=(1914182220, 955398943)\n",
      "train.csv:7000 (userId, eventId)=(2071842684, 1076364848)\n",
      "train.csv:7500 (userId, eventId)=(2217853337, 3051438735)\n",
      "train.csv:8000 (userId, eventId)=(2338481531, 2525447278)\n",
      "train.csv:8500 (userId, eventId)=(2489551967, 520657921)\n",
      "train.csv:9000 (userId, eventId)=(2650493630, 87962584)\n",
      "train.csv:9500 (userId, eventId)=(2791418962, 4223848259)\n",
      "train.csv:10000 (userId, eventId)=(2903662804, 2791462807)\n",
      "train.csv:10500 (userId, eventId)=(3036141956, 3929507420)\n",
      "train.csv:11000 (userId, eventId)=(3176074542, 3459485614)\n",
      "train.csv:11500 (userId, eventId)=(3285425249, 2271782630)\n",
      "train.csv:12000 (userId, eventId)=(3410667855, 1063772489)\n",
      "train.csv:12500 (userId, eventId)=(3531604778, 2584839423)\n",
      "train.csv:13000 (userId, eventId)=(3686871863, 53495098)\n",
      "train.csv:13500 (userId, eventId)=(3833637800, 2415873572)\n",
      "train.csv:14000 (userId, eventId)=(3944021305, 2096772901)\n",
      "train.csv:14500 (userId, eventId)=(4075466480, 3567240505)\n",
      "train.csv:15000 (userId, eventId)=(4197193550, 1628057176)\n",
      "生成预测数据...\n",
      "\n",
      "test.csv:500 (userId, eventId)=(182290053, 2529072432)\n",
      "test.csv:1000 (userId, eventId)=(433510318, 4244463632)\n",
      "test.csv:1500 (userId, eventId)=(632808865, 2845303452)\n",
      "test.csv:2000 (userId, eventId)=(813611885, 2036538169)\n",
      "test.csv:2500 (userId, eventId)=(1010701404, 303459881)\n",
      "test.csv:3000 (userId, eventId)=(1210932037, 2529072432)\n",
      "test.csv:3500 (userId, eventId)=(1452921099, 2705317682)\n",
      "test.csv:4000 (userId, eventId)=(1623287180, 1626678328)\n",
      "test.csv:4500 (userId, eventId)=(1855201342, 2603032829)\n",
      "test.csv:5000 (userId, eventId)=(2083900381, 2529072432)\n",
      "test.csv:5500 (userId, eventId)=(2318415276, 2509151803)\n",
      "test.csv:6000 (userId, eventId)=(2528161539, 4025975316)\n",
      "test.csv:6500 (userId, eventId)=(2749110768, 4244406355)\n",
      "test.csv:7000 (userId, eventId)=(2927772127, 1532377761)\n",
      "test.csv:7500 (userId, eventId)=(3199685636, 1776393554)\n",
      "test.csv:8000 (userId, eventId)=(3393388475, 680270887)\n",
      "test.csv:8500 (userId, eventId)=(3601169721, 154434302)\n",
      "test.csv:9000 (userId, eventId)=(3828963415, 3067222491)\n",
      "test.csv:9500 (userId, eventId)=(4018723397, 2522610844)\n",
      "test.csv:10000 (userId, eventId)=(4180064266, 2658555390)\n"
     ]
    }
   ],
   "source": [
    "RS = RecommonderSystem()\n",
    "print (\"生成训练数据...\\n\")\n",
    "generateRSData(RS,train=True,  header=True)\n",
    "\n",
    "print (\"生成预测数据...\\n\")\n",
    "generateRSData(RS, train=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "时间、地点等特征都没有处理了，可以考虑用户看到event的时间与event开始时间的差、用户地点和event地点的差异。。。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
